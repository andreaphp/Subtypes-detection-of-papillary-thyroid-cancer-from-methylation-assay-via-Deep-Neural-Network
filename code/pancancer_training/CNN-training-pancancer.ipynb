{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "046cedcb-c71b-46da-ac5e-c5f26d947da8",
   "metadata": {},
   "source": [
    "Pancancer Training - We use 80% of the samples for training and 20% for testing, we ensure with stratify that all tissue are represented both in train and test with same percentages. IMPORTANT: The code assumes that the .env file in root directory contains both the location of Datasets folder (where GDC_samples.csv resides) and the location of raw GDC samples in GDC_PATH variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df33e15-0ebf-4b2a-8537-667404d07b3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras import Input,Model\n",
    "from keras.layers import Dense, Conv1D, AveragePooling1D, Flatten, Activation, Concatenate, Dropout, AlphaDropout, GlobalAveragePooling1D\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Add the parent directory to access ENV variables\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "#Import of necessary paths ( GDC data Path and Dataset folder)\n",
    "from config import GDC_PATH,THYROID_PATH, TENSORBOARD_PATH, MODEL_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253d8bf5-fd54-4603-ae55-77388c7df253",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loading GDC Pancancer Data and Train/Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ff69d1-5821-493e-965e-f48ec7425bde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples_dataframe_path = Path(THYROID_PATH,'GDC_samples.csv')\n",
    "samples_dataframe = pd.read_csv(samples_dataframe_path,index_col=0)\n",
    "#Add GDC PATH to the Path column\n",
    "samples_dataframe['Path']=[ Path(GDC_PATH,path ) for path in samples_dataframe['Path']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842d8b2e-8b36-4b96-8a5c-4df115c196ed",
   "metadata": {},
   "source": [
    "To stratify taking account of both normal/cancer imbalance and tissue of origin, we create a dummy placeholder variable that accounts for both conditions. Num_ID is the number of the GDC/TCGA study, where only one tissue is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cc92df-9a0c-4436-b407-0fb6d092916f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples_dataframe['dummy'] = samples_dataframe['Num_ID'].astype(str) + '_'+ samples_dataframe['Target'].astype(str)\n",
    "\n",
    "train, test = train_test_split(samples_dataframe, test_size=0.2, random_state=2046, stratify=samples_dataframe[['dummy']])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b57c57-2afb-4aee-ad7b-526ab5fb7edc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Data Loading Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b9c72b-f133-4e95-a15d-955ea2a7936e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744828ff-344e-414e-abd2-cdf2c9091b24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataGen(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, df, X_col, y_col,\n",
    "                 batch_size,\n",
    "                 input_size=(485577,1),\n",
    "                 shuffle=True, to_fit = True):\n",
    "        \n",
    "        self.df = df.copy()\n",
    "        self.X_col = X_col\n",
    "        self.y_col = y_col\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.shuffle = shuffle\n",
    "        self.to_fit = to_fit\n",
    "        \n",
    "        self.n = len(self.df)\n",
    "        self.n_study = df[y_col['study']].nunique()\n",
    "        self.n_target = df[y_col['target']].nunique()\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    def __get_input(self, path):\n",
    "        temp = pd.read_csv(path,sep='\\t',index_col=0,names=['value'])\n",
    "        temp = temp.reindex(sorted(temp.index))\n",
    "        temp = temp.fillna(0.0)\n",
    "        return temp\n",
    "\n",
    "    \n",
    "    def __get_output(self, label, num_classes):\n",
    "        return tf.keras.utils.to_categorical(label, num_classes=num_classes)\n",
    "    \n",
    "    def __get_data(self, batches):\n",
    "        # Generates data containing batch_size samples\n",
    "\n",
    "        path_batch = batches[self.X_col['path']]\n",
    "        #study_batch = batches[self.y_col['study']]\n",
    "        target_batch = batches[self.y_col['target']]\n",
    "\n",
    "        \n",
    "        \n",
    "        X_batch = np.asarray([self.__get_input(path) for path in path_batch])\n",
    "        \n",
    "        if self.to_fit == True:\n",
    "        \n",
    "            #y0_batch = np.asarray([self.__get_output(y, self.n_study) for y in study_batch])\n",
    "            y_batch = np.asarray([y for y in target_batch])\n",
    "        \n",
    "            return (X_batch, y_batch)\n",
    "        else:\n",
    "            return X_batch\n",
    "    def __getitem__(self, index):\n",
    "        batches = self.df[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X, y = self.__get_data(batches)        \n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1ca6b8-be6f-4637-9607-317387344e08",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train and Test Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eda8065-3656-4cdf-b18f-a574cdc82027",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "traingen = CustomDataGen(train,X_col={'path':'Path'},y_col={'study':'Num_ID','target':'Target'},batch_size=batch_size)\n",
    "validgen = CustomDataGen(test,X_col={'path':'Path'},y_col={'study':'Num_ID','target':'Target'},batch_size=batch_size)\n",
    "num_classes = traingen.n_study\n",
    "\n",
    "pos = np.sum(train['Target']==1)\n",
    "neg = np.sum(train['Target']==0)\n",
    "total = pos+neg\n",
    "weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa8ab11-6953-47a2-a425-a1c2a6cee290",
   "metadata": {},
   "source": [
    "# CNN - 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4442da0e-fdf5-4eb5-ae47-ba596442864c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conv(i, filters=16, kernel_size=5, strides=1):\n",
    "    #, activity_regularizer=keras.regularizers.l2(1e-6)\n",
    "    i = keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, strides=strides, padding='same',kernel_initializer='glorot_uniform')(i)\n",
    "    i = keras.layers.BatchNormalization()(i)\n",
    "    i = keras.layers.LeakyReLU()(i)\n",
    "    i = keras.layers.SpatialDropout1D(0.1)(i)\n",
    "    return i\n",
    "\n",
    "def residual_unit(x, filters, layers=3):\n",
    "    inp = x\n",
    "    for i in range(layers):\n",
    "        x = conv(x, filters)\n",
    "    return keras.layers.add([x, inp])\n",
    "\n",
    "def conv_block(x, filters, strides):\n",
    "    x = conv(x, filters)\n",
    "    #x = dense_residual_unit(x, filters)\n",
    "    x = residual_unit(x, filters)\n",
    "    if strides > 1:\n",
    "        x = keras.layers.AveragePooling1D(strides, strides)(x)\n",
    "    return x\n",
    "\n",
    "def get_uncompiled_model(input_shape = (485577,1)):\n",
    "    inp = keras.layers.Input(shape=input_shape, dtype=tf.float32)\n",
    "\n",
    "    conv_1 = conv_block(inp, 16, 1)\n",
    "    avgpool1 = AveragePooling1D(\n",
    "        pool_size=2, strides=2, name='avgpool1',\n",
    "        data_format=\"channels_last\")(conv_1)\n",
    "    conv_2 = conv_block(avgpool1, 32, 2)\n",
    "    avgpool2 = AveragePooling1D(\n",
    "        pool_size=2, strides=2, name='avgpool2',\n",
    "        data_format=\"channels_last\")(conv_2)\n",
    "    conv_3 = conv_block(avgpool2, 64, 2)\n",
    "    \n",
    "    flat = Flatten()(conv_3)\n",
    "    output= Dense(1, activation='sigmoid',name='output')(flat)\n",
    "  \n",
    "\n",
    "    model = keras.models.Model(inp, output)\n",
    "    return model\n",
    "\n",
    "def get_compiled_model(metrics=None):\n",
    "    \n",
    "    if(metrics is None):\n",
    "        metrics = [\n",
    "              keras.metrics.TruePositives(name='tp'),\n",
    "              keras.metrics.FalsePositives(name='fp'),\n",
    "              keras.metrics.TrueNegatives(name='tn'),\n",
    "              keras.metrics.FalseNegatives(name='fn'), \n",
    "              keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "              keras.metrics.Precision(name='precision'),\n",
    "              keras.metrics.Recall(name='recall'),\n",
    "              keras.metrics.AUC(name='auc'),\n",
    "              keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "        ]\n",
    "        \n",
    "    model = get_uncompiled_model()\n",
    "    model.compile(loss='binary_crossentropy',optimizer=\"adam\",metrics=metrics)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a48dde9-2277-47e4-8596-7d79003ff9d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Continue the training if checkpoint exist, otherwise start training from scratch\n",
    "\n",
    "def make_or_restore_model(checkpoint_dir = \"ckpt\"):\n",
    "    # Either restore the latest model, or create a fresh one\n",
    "    # if there is no checkpoint available.\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "    checkpoints = [checkpoint_dir + \"/\" + name for name in os.listdir(checkpoint_dir)]\n",
    "    if checkpoints:\n",
    "        latest_checkpoint = max(checkpoints, key=os.path.getctime)\n",
    "        print(\"Restoring from\", latest_checkpoint)\n",
    "        return keras.models.load_model(latest_checkpoint)\n",
    "    print(\"Creating a new model\")\n",
    "    return get_compiled_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c684e228-3db4-42d2-9dea-25d4419e14e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model = get_uncompiled_model() #Get the uncompiled model\n",
    "#model.summary() #Summary of model before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bda6a7-fa1b-4989-9811-7e9fe33bed3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#keras.utils.plot_model(model) #Plot the model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c199b468-a2df-483f-8c54-fdf1e323bd72",
   "metadata": {},
   "source": [
    "# Pan-cancer - All Samples with Leaky RELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124aeac7-d994-4504-8843-516295a8a27c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_logdir = Path(TENSORBOARD_PATH)\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir() # e.g., './my_logs/run_2025_03_16-11_28_43'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195769dc-ff4f-4533-b244-3cd12c0bd2a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = 'ckpt-leakyrelu'\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "        filepath= os.path.join(checkpoint_dir,\"ckpt-loss={loss:.2f}\"), save_freq=100)\n",
    "\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "lr_schedule = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    patience=5,\n",
    "    factor=0.2,\n",
    "    min_lr=0.0000001)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_auc', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)\n",
    "\n",
    "callbacks = [checkpoint_cb,early_stopping_cb,tensorboard_cb,lr_schedule]\n",
    "model = make_or_restore_model(checkpoint_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64c8c9f-2b5d-4d50-b5b4-984b3c48159c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_history = model.fit(traingen, epochs=100, batch_size = batch_size,validation_data = validgen, callbacks=callbacks, class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4034de-19a4-4563-a5bd-62d86bed6edc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Save training history\n",
    "history_df = pd.DataFrame(model_history.history)\n",
    "history_df.to_csv(\"fit_history/pan-cancer-leaky-relu.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f645cfb-6dad-4922-ba2f-bd1e4cd8084f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Save Model\n",
    "model.save(os.path.join(MODEL_PATH,\"pan-cancer-leaky-relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c9dce1-3589-4f0f-b069-e1a9773784ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pan-cancer - All samples with Standard RELU "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131ce4fc-3196-402b-988a-086cfefaf41e",
   "metadata": {},
   "source": [
    "To change the Leaky RELU to standard RELU we just need to replace the conv function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad10d5fc-f2e2-4dcb-8958-09360b68b5f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conv(i, filters=16, kernel_size=5, strides=1):\n",
    "    #, activity_regularizer=keras.regularizers.l2(1e-6)\n",
    "    i = keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, strides=strides, padding='same',kernel_initializer='glorot_uniform')(i)\n",
    "    i = keras.layers.BatchNormalization()(i)\n",
    "    i = keras.layers.ReLU()(i)\n",
    "    i = keras.layers.SpatialDropout1D(0.1)(i)\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fd1b80-22d7-4d9c-ad7e-74950b147c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = Path(TENSORBOARD_PATH)\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir() # e.g., './my_logs/run_2025_03_16-11_28_43'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579af801-595b-45fb-8aa9-72891e078f6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = 'ckpt-standardrelu'\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "        filepath= os.path.join(checkpoint_dir,\"ckpt-loss={loss:.2f}\"), save_freq=100)\n",
    "\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "lr_schedule = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    patience=5,\n",
    "    factor=0.2,\n",
    "    min_lr=0.0000001)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_auc', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)\n",
    "\n",
    "callbacks = [checkpoint_cb,early_stopping_cb,tensorboard_cb,lr_schedule]\n",
    "model = make_or_restore_model(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93913b65-bde4-44e1-826d-157f5fcdf0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model.fit(traingen, epochs=100, batch_size = batch_size,validation_data = validgen, callbacks=callbacks, class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23926ed2-ed03-48e0-bec0-dcf02e419613",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save training history\n",
    "history_df = pd.DataFrame(model_history.history)\n",
    "history_df.to_csv(\"fit_history/pan-cancer-standard-relu.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689d30ff-87b9-498f-9ea3-3c10df3e8bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(MODEL_PATH,\"pan-cancer-standard-relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c01dcda-b6de-4449-9917-1cf6c29ab7ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pan cancer - Solid Tumors with Standard RELU "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f173a2-1ea8-433b-8ef7-478b09d24778",
   "metadata": {},
   "source": [
    "We reuse the model with standard relu and we remove blood samples from the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17d6100-d815-40b6-a3ff-b2ad9caa5bd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "blood_studies = ('TCGA-LAML','TARGET-AML')\n",
    "solid_samples = samples_dataframe[~samples_dataframe['Project.ID'].isin(blood_studies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5220cb3d-d0c5-466e-827a-e94d1324d41b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(solid_samples, test_size=0.2, random_state=2046, stratify=solid_samples[['dummy']])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7bbb6c-9638-4a67-a8b6-9b73401c1733",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "traingen = CustomDataGen(train,X_col={'path':'Path'},y_col={'study':'Num_ID','target':'Target'},batch_size=batch_size)\n",
    "validgen = CustomDataGen(test,X_col={'path':'Path'},y_col={'study':'Num_ID','target':'Target'},batch_size=batch_size)\n",
    "num_classes = traingen.n_study\n",
    "\n",
    "pos = np.sum(train['Target']==1)\n",
    "neg = np.sum(train['Target']==0)\n",
    "total = pos+neg\n",
    "weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bd5d8c-a8f1-4e07-9382-3c5cc1b871c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_logdir = Path(TENSORBOARD_PATH)\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir() # e.g., './my_logs/run_2025_03_16-11_28_43'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cceb04c-196b-4cf2-9b5e-a32bdd70bda0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = 'ckpt-solidonly'\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "        filepath= os.path.join(checkpoint_dir,\"ckpt-loss={loss:.2f}\"), save_freq=100)\n",
    "\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "lr_schedule = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    patience=5,\n",
    "    factor=0.2,\n",
    "    min_lr=0.0000001)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_auc', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)\n",
    "\n",
    "callbacks = [checkpoint_cb,early_stopping_cb,tensorboard_cb,lr_schedule]\n",
    "model = make_or_restore_model(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4788495f-7b4c-4db0-a891-744b807007b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model.fit(traingen, epochs=100, batch_size = batch_size,validation_data = validgen, callbacks=callbacks, class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b251de26-8592-4b78-86e6-d59acddc493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save training history\n",
    "history_df = pd.DataFrame(model_history.history)\n",
    "history_df.to_csv(\"fit_history/pan-cancer-solid-only.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9d709b-4e15-4a55-882a-b428b15e26d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(MODEL_PATH,\"pan-cancer-solid-only\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_gpu]",
   "language": "python",
   "name": "conda-env-tf_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
